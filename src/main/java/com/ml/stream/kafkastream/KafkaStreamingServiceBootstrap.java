package com.ml.stream.kafkastream;

import java.util.Properties;
import java.util.UUID;

import org.apache.avro.generic.GenericRecord;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.processor.Processor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.ml.stream.kafkastream.constants.Constants;
import com.ml.stream.kafkastream.exception.handlers.DeserializationExceptionHandler;
import com.ml.stream.kafkastream.serde.GenericAvroSerde;
import com.ml.stream.kafkastream.stream.StreamScorer;
import com.ml.stream.kafkastream.utils.PropertiesUtil;

/**
 * @author Umesh.Menon
 * This is a bootstrap class will set up all the necessary prerequisites to run a scoring service.
 * Mainly it sets up the configuration to run. i.e. load the property file and set the variables 
 * that are needed to run a streaming.
 */
public class KafkaStreamingServiceBootstrap {
	 private static Logger logger = LoggerFactory.getLogger(KafkaStreamingServiceBootstrap.class.getSimpleName());
		
	 public Properties appProps;
	 //private static Properties kafkaProps;
	 private static String env="";
	 private static String configFile;
	 private int threadCount=10;
	 private String applicationId;
	 private Processor<String, GenericRecord> processor = null; 
	 private String source = "";
	 private String sink = "";
	 private StreamScorer scorer = null;
	 
	 // Kafka Topology builder allows to add many processors, but that's alow level api and 
	 // here for simplicity sake we are just using Kafka DSL and 
	 // keeping only once processor which is nothing but our scorer.
	 
		/**
	  * Constructor takes a configuration
	  */
	 public KafkaStreamingServiceBootstrap(String[] args){
		 // REVISIT: We can use ConfigFactory to load Properties file
	     //config = ConfigFactory.load(configPath);
	 	 // set up the logger
	 	 //logger = LoggerFactory.getLogger(this.getClass().getSimpleName());
	 	 //this.appProps = appProps;
	 	 //logger.debug("Loaded properties {}", appProps);
	     //this.kafkaProps = kafkaProps;
	 	
	 	 // parse the input arguments
	     parseArgs(args);
	     
	     // load the property filer
	     this.appProps = loadProps();
	     
	     // initialize
	     this.initialize();
	 }
	 
	 /**
	  * Initializes the class variables
	  */
	 public void initialize(){
	 	logger.info("Initializing the service...");
	 	this.setDefaults();
	    this.setKafkaConfs();
	    logger.info("Intialization completed.");
	 }
	
	 /**
	  * Sets the default values to variables
	  */
	 private void setDefaults(){
	 	
	 	Boolean bSet = true;
	 	// check if application id is given
	 	if (this.appProps.containsKey(Constants.APPLICATION_ID)){
	 		if (this.appProps.getProperty(Constants.APPLICATION_ID) == null){
	 			bSet = false;
	 		}
	 	}else{
	 		bSet = false;
	 	}
	 	// sets the application id in the Propeties file
	 	this.applicationId = this.appProps.getProperty(Constants.APPLICATION_ID, UUID.randomUUID().toString());
	 	this.applicationId = (String) this.appProps.putIfAbsent(Constants.APPLICATION_ID, this.applicationId);
	 	
	 	if (!bSet){
	 		logger.warn("The property application.id is not set in the properties file. It is a good "
	 				+ "practise to set a unique application.id that's appropriate to distinguish your application.");
	 		logger.info("Following autogenerated id will be used:" + this.applicationId);
	 	}
	 	logger.info("Application Id: " + this.applicationId);
	 	
	 }
	 
	 /**
	  * Sets some additional configurations for Kafka
	  */
	 private void setKafkaConfs(){
	     logger.info("Setting additional Kafka configurations...");
	     this.appProps.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
	     this.appProps.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, GenericAvroSerde.class);
	
	     // Set Source and AND Deserialization Handler
	     this.appProps.put(Constants.SRC_TOPIC,
	     		this.appProps.getProperty(Constants.SRC_TOPIC));
	     this.appProps.put(StreamsConfig.DEFAULT_DESERIALIZATION_EXCEPTION_HANDLER_CLASS_CONFIG, DeserializationExceptionHandler.class.getCanonicalName());
	     this.appProps.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE);
	     logger.info("Successfuly set additional Kafka configurations");
	 }
	
	 /**
	  * For future extension to work with any kind of processing logic and not just scorers
	  * Adds a single processor class which will be used by the KafkaStreamingScorerService
	  * 
	  * @param processr
	  * @return
	  */
	 public KafkaStreamingServiceBootstrap addProcessor(Processor<String, GenericRecord> processr){
			this.processor = processr;
			return this;
		}  
	 
	 /**
	  * To keep it simple, we are just adding one single scorer class
	  * So addProcessor will not be used 
	  * @param scorer
	  * @return
	  */
	 public KafkaStreamingServiceBootstrap addScorer(StreamScorer scorer){
	 	this.scorer = scorer;
		return this;
	 }
	 
	 /**
	  * Getter for properties
	  * @return
	  */
	 public Properties getAppProperties(){
		 return this.appProps;
	 }
	 
	 /**
	  * Loads the property from the config file
	  * @return
	  */
	 public static Properties loadProps(){
	 	Properties appProps = null;
	 	logger.info("Loading properties...");
	 	if (configFile != null && !configFile.equals("")){
	 		appProps = PropertiesUtil.loadFromFile(configFile);
	 	}else{
	 		// Load kafka properties
	         //config = ConfigFactory.load(configPath);
	         //Properties kafkaProps = PropertiesUtil.load("kafka" + (env!=""?"_"+env:""));
	         appProps = PropertiesUtil.load("application" + (env!=""?"_"+env:""));
	 	}
	     
	     logger.debug("Properties set for Stream job:{}", appProps);
	     return appProps;
	 }
	 
	 /**
	  * Parses the input arguments
	  * @param args
	  */
	 public static void parseArgs(String[] args){
	 	logger.info("Parsing arguments...");
	     try{
	         for (int i = 0; i < args.length; i++) {
	             String s = args[i];
	             String sarg = args[i];
	             switch (s) {
	                 case "--env": env = sarg;
	                 case "--config_file": configFile = sarg;
	                 default:
	                     System.out.println("ERROR: Unknown command line argument: " + s);
	                     usage();
	             }
	         }
	     }catch (Exception e) {
	         e.printStackTrace();
	         usage();
	     }
	     logger.info("Parsing arguments completed.");
	 }
	
	 /**
	  * Displays the usage
	  */
	 public static void usage() {
	     System.out.println("");
	     System.out.println("Usage:  java [...java args...] KafkaStreamingServiceLauncher --env Environment name that is appended in application-<<env>>.properties  --config_file Path to .properties file");
	     System.out.println("");
	     System.exit(1);
	 }
}
